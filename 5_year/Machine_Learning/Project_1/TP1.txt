Attention:
- Do not edit this file in text editors like Word. Use a plain text editor only. In case of doubt, you can use Spyder as a text editor.
- Do not change the structure of this file. Just fill in your answers in the places provided (After the R#: tag).
- You can add lines in the spaces for your answers but your answers should be brief and straight to the point.

QUESTIONS:

Q1: Considering the datasets provided, explain the need to standardize the attribute values.
R1: Consideramos que a necessidade de standardização existe quando o dataset em questão apresenta atributos de diferente magnitude e/ou diferentes unidades de medida, visto que os modelos aprendizagem podem sofrer alguns problemas caso as caracteristicas anteriores se verifiquem.
No primeiro dataset existe quer uma enorme variação de valores, quer a presença de unidades diferentes tanto entre os atributos em si como tambem no valor a prever.
No segundo dataset é necessesario a standardização pois os atributos apresentam unidades de medida diferentes.


Q2: Explain how you calculated the parameters for standardization and how you used them in the test set.
R2: Para determinarmos os parâmetros para a standardização calculámos o desvio padrão e a média de cada feature do training set. Depois, ao valor real da feature do traning e do test set foi subtraído o valor da média da amostra e o resultado foi dividido pelo desvio padrão. 



Q3: Classification: Explain how you calculated the prior probability of an example belonging to a class (the probability before taking into account the attribute values ​​of the example) in your Naïve Bayes classifier implementation. You may include a relevant piece of your code if this helps you explain.
R3:É a probabilidade de pertercer a classe 0 ou 1.
 C0_log = np.log(len(xs_0) / len(X_train_set))
 C1_log = np.log(len(xs_1) / len(X_train_set))
 neste caso len(xs_0) corresponde ao numero de elementos do set com classificação 0, que depois é dividido pelo numero total de elementos.(aplica se o mesmo para c1_log)


Q4: Explain how your Naïve Bayes classifier predicts the class to which a test example belongs. You may include a relevant piece of your code if this helps you explain.
R4: O classificador tem como objetivo prever a classe a que um exemplo de teste pertence calculando o somatorio da probabilidade de cada feature para cada classe. A este valor é somada a probabilidade de pertencer à própria classe.
No final é escolhida a classe que contem o maior valor.

    C0_log = np.log(len(xs_0) / len(X_train))
    C1_log = np.log(len(xs_1) / len(X_train))
    
    probs0 = np.full(len(X_test),C0_log) 
    probs1 = np.full(len(X_test),C1_log)
    
    for feats in range(X_train.shape[1]):
        
        kde = KernelDensity(kernel= "gaussian", bandwidth=bandwith_value)
        kde.fit(xs_0[:,[feats]])
        probs0 += kde.score_samples(X_test[:,[feats]])
        
        kde = KernelDensity(kernel= "gaussian", bandwidth=bandwith_value)
        kde.fit(xs_1[:,[feats]])
        probs1 += kde.score_samples(X_test[:,[feats]])
        
    pred = np.zeros(len(X_test))
    for i in range(len(X_test)):
        if(probs0[i] < probs1[i]):
            pred[i] = 1

Q5: Explain the effect of the bandwidth parameter on your classifier.
R5:A bandwith controla a vizinhanca, quanto maior a bandwith maior vai ser o peso dos pontos que estão afastados do valor de treino(vizinhança), e quanto menor for a bandwith mais restringida vai estar a vizinhança.


Q6: Explain how you determined the best bandwidth parameter for your classifier. You may include a relevant piece of your code if this helps you explain.
R6: Determinámos o valor óptimo para a bandwidth através da realização de ciclos a percorrer um range de valores que varia entre 0.2 e 0.6, que eram atribuídos aos parâmetros.
Executamos cross validation sobre o training set, com 5 folds, comparando os scores que iam sendo obtidos, guardando o score óptimo e a bandwitch ideal.

for b in range(2,62,2):
        bandwith_value=b/100
        tr_err = va_err = 0
        for train_ix,valid_ix in kf.split(Y_train,Y_train):
            r,v= calc_fold(X_train,Y_train,train_ix,valid_ix, bandwith_value)
            tr_err += r
            va_err += v
        if bestVal>va_err/folds:
            bestVal = va_err/folds
            bestband = bandwith_value


Q7: Explain how you obtained the best hypothesis for each classifier after optimizing all parameters.
R7: Depois de obtermos a melhor bandwitch realizamos outra classificação em todo o traning set.


Q8: Show the best parameters, the estimate of the true error for each hypothesis you obtained (your classifier and the one provided by the library), the ranges in the expected number of errors given by the approximate normal test, the McNemar test values, and discuss what you can conclude from this.
R8: Gaussian Naive Bayes:
 True Error: 0.09462710505212513 
 Normal Test: 97.74133517328086 , 138.25866482671913 

Naive Bayes:
 Best Bandwith: 0.36 
 True Error: 0.0601443464314354 
 Normal Test: 58.54426510586128 , 91.45573489413871 

Naive Bayes vs Gaussian Naive Bayes
 McNemar Test: 34.588235294117645 

Olhando para os dados obtidos de todos os testes, é possível dizer que os classificadores que tiveram tunning dos parâmetros foram os que obteram melhores resultados, ou seja o tunning dos parâmetros é bastante importante para ter um bom classificador.


Q9: Regression: Explain what experiments and plots gave you good evidence to choose a given model degree. 
R9: Observando o validation error é um bom fator para a escolha do melhor degree assim como a observação do plot entre os valores esperados versus os obtidos.


Q10: In the case of your mean squared error plot explain why one of the error curves is always decreasing, while the other is not.
R10: Com o aumento dos degree o modelo adapta-se aos detalhes do training set fazendo com que a curva do modelo se afaste de valores fora da amostra usada para o treino.  


Q11: In the plots of the true versus predicted values, where would be all the points when predicted by an ideal regressor? Justify.
R11: Teriam que coinsidir com uma linha de declive 1 que passa pela origem porque com um regressor ideal os valores previstos seriam iguais aos aos valores reais resultando assim nesta mesma reta.


Q12: Explain your validation procedure and comment on the true error of your chosen model for unseen data.
R12: O processo de validação é feito pelo KFold cross-validation pois permite avaliar o proprio modelo, de outra maneira(split entre train, validation e test) estariamos a avaliar uma hipotese especifica, não o modelo.


